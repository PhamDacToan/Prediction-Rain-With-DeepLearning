import streamlit as st
import pandas as pd
import numpy as np
import math
# Data Visualization
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder,StandardScaler
# ML algorithms
from sklearn.linear_model import LinearRegression,LogisticRegression, Lasso,Ridge
from sklearn.ensemble import RandomForestRegressor
# Model Selection for Cross Validation
from sklearn.model_selection import train_test_split,StratifiedKFold, KFold,cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import LocalOutlierFactor
# Machine Learning metrics
from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score,mean_squared_error,mean_absolute_error,r2_score
# Hiding warnings
import warnings
warnings.filterwarnings("ignore")
#emojis

st.sidebar.markdown('''
                    # Selection
                    - <a href='#dataset' style='text-decoration:none;font-size:25px;font-weight: 800;'>Dataset</a>
                    <br>
                    - <a href='#prediction-with-models' style='text-decoration:none;font-size:25px;font-weight: 800;'>Prediction with models</a>
                    
                    ''', unsafe_allow_html=True)

st.title("Rain Predict")
# st.set_page_config(page_title=' Raining Predict', page_icon='üå®')

st.balloons()

st.title("üå§ X√ÇY D·ª∞NG M√î H√åNH H·ªíI QUY V√Ä D·ª∞ ƒêO√ÅN TH·ªúI TI·∫æT", )
st.markdown('##')

df= pd.read_csv('C:\@@Learn\Streamlit with python\Data\weatherAUS.csv')

st.header('DATASET')
st.caption('T·∫≠p d·ªØ li·ªáu m·∫´u')
st.dataframe(df)


st.text('''
    C√°c thu·ªôc t√≠nh c·ªßa Dataset :
    ‚Ä¢ Date: Ng√†y th√°ng nƒÉm, Object
    ‚Ä¢ Location: V·ªã tr√≠, Object
    ‚Ä¢ MinTemp: Nhi·ªát ƒë·ªô t·ªëi thi·ªÉu, float64
    ‚Ä¢ MaxTemp: Nhi·ªát ƒë·ªô t·ªëi ƒëa, Object
    ‚Ä¢ Rainfall: L∆∞·ª£ng m∆∞a, float64
    ‚Ä¢ Evaporation: Bay h∆°i, float64
    ‚Ä¢ Sunshine: √Ånh s√°ng m·∫∑t tr·ªùi, float64
    ‚Ä¢ WindGustDir: Gi√≥, Object
    ‚Ä¢ WindGustSpeed: T·ªëc ƒë·ªô gi√≥, Object
    ‚Ä¢ WindDir9am: Gi√≥ m·∫°nh l√∫c 9am, float64
    ‚Ä¢ WindDir3pm: Gi√≥ m·∫°nh l√∫c 3pm, Float
    ‚Ä¢ WindSpeed9am: T·ªëc ƒë·ªô gi√≥ l√∫c 9am, float64
    ‚Ä¢ WindSpeed3pm: T·ªëc ƒë·ªô gi√≥ l√∫c 3pm, float64
    ‚Ä¢ Humidity9am: ƒê·ªô ·∫©m 9 gi·ªù s√°ng, float64
    ‚Ä¢ Humidity3pm: ƒê·ªô ·∫©m l√∫c 3 gi·ªù pm, float64
    ‚Ä¢ Pressure9am: √Åp l·ª±c l√∫c 9am, Object
    ‚Ä¢ Pressure3pm: √Åp l·ª±c l√∫c 3pm, Object
    ‚Ä¢ Cloud9am: ƒê√°m m√¢y l√∫c 9am, float64
    ‚Ä¢ Cloud3pm: ƒê√°m m√¢y l√∫c 3pm, Object
    ‚Ä¢ Temp9am: Nhi·ªát ƒë·ªô l√∫c 9am, Object
    ‚Ä¢ Temp3pm: Nhi·ªát ƒë·ªô l√∫c 3pm, float64
    ‚Ä¢ RainToday: M∆∞a h√¥m nay, float64
    ‚Ä¢ RainTomorrow: M∆∞a ng√†y mai, float64	
''')

st.header('IMPORT LIBRARY')
st.code('''
#Import library
import datetime
import pandas as pd
import numpy as np
import math
# Data Visualization
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder,StandardScaler
# ML algorithms
from sklearn.linear_model import LinearRegression,LogisticRegression, Lasso,Ridge
from sklearn.ensemble import RandomForestRegressor
from catboost import CatBoostRegressor
# Model Selection for Cross Validation
from sklearn.model_selection import train_test_split,StratifiedKFold, KFold,cross_val_score
from keras.layers import Dense, BatchNormalization, Dropout, LSTM
from keras.models import Sequential
from keras.utils import to_categorical
from sklearn.model_selection import GridSearchCV
from keras.optimizers import Adam
from sklearn.neighbors import LocalOutlierFactor
# Machine Learning metrics
from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score,mean_squared_error,mean_absolute_error,r2_score
from keras import callbacks
# Hiding warnings
import warnings
warnings.filterwarnings("ignore")
#Conect google drive
from google.colab import drive
drive.mount('/content/drive')
        ''')
st.text('V√¨ th∆∞ vi·ªán catboost kh√¥ng c√≥ s·∫µn n√™n s·∫Ω ta s·∫Ω install')
st.code('!pip install catboost')

st.subheader('Th√¥ng tin chi ti·∫øt v·ªÅ c√°c thu·ªôc t√≠nh c≈©ng nh∆∞ ki·ªÉu d·ªØ li·ªáu c·ªßa n√≥')

st.table(df.dtypes)

st.header('TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU')

st.subheader('Bi·ªÉu ƒë·ªì c·ªôt ƒë·∫øm m·ª•c ti√™u (target)')

def v_line_target():
    cols =['green','blue']
    fig = plt.figure(figsize=(10, 4))
    plot =sns.countplot(x=df['RainTomorrow'], palette= cols)
    st.pyplot(fig)
v_line_target()

st.subheader('Bi·ªÉu ƒë·ªì t∆∞∆°ng quan gi·ªØa c√°c thu·ªôc t√≠nh')

def v_Hemap():
    a=df.select_dtypes(exclude=['object'])
    corrmat = a.corr()
    cmap= sns.diverging_palette(260, -10, s=50, l=75,n =6, as_cmap=True)
    plt.figure(figsize=(15, 15))
    sns.heatmap(corrmat, cmap= cmap, annot= True, square =True)
    st.set_option('deprecation.showPyplotGlobalUse', False)
    st.pyplot()

v_Hemap()

st.text('Check ƒë·ªô d√†i c·ªßa c√°c chu·ªói c·ªôt "Date"')

lengths= df['Date'].str.len()

value_counts = lengths.value_counts()
st.code(value_counts)

st.text('Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu c·ªßa c·ªôt Date ƒë·ªÉ t√°ch ra c·ªôt Year, Month, Day')
# Chuy·ªÉn type int64 th√†nh datetime c·ªßa c·ªôt Date
df['Date']=pd.to_datetime(df['Date'])
# T·∫°o 1 c·ªôt cho nƒÉm (year)
df['year']= df.Date.dt.year

# M√£ h√≥a d·ªØ li·ªáu ng√†y, th√°ng theo tham s·ªë tu·∫ßn ho√†n ƒë·ªÉ h·ªï tr·ª£ thi·∫øt l·∫≠p m√¥ h√¨nh
def encode(data,col, max_val):
  df[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)
  df[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)
  return df
df['month'] = df.Date.dt.month
df= encode(df,'month',12)

df['day'] = df.Date.dt.day
df= encode(df, 'day',31)

st.code('''
# Chuy·ªÉn type int64 th√†nh datetime c·ªßa c·ªôt Date
df['Date']=pd.to_datetime(df['Date'])
# T·∫°o 1 c·ªôt cho nƒÉm (year)
df['year']= df.Date.dt.year

# M√£ h√≥a d·ªØ li·ªáu ng√†y, th√°ng theo tham s·ªë tu·∫ßn ho√†n ƒë·ªÉ h·ªï tr·ª£ thi·∫øt l·∫≠p m√¥ h√¨nh
def encode(data,col, max_val):
  df[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)
  df[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)
  return df
df['month'] = df.Date.dt.month
df= encode(df,'month',12)

df['day'] = df.Date.dt.day
df= encode(df, 'day',31)

df.head()
''')

st.dataframe(df.iloc[:, 23:])

st.subheader('Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi c·ªßa ng√†y trong kho·∫£ng 1 nƒÉm')
def v_line_d():
    section = df[:360]
    plt.figure(figsize=(10, 6))
    tm = section["day"].plot(color="lightgreen")
    tm.set_title("Distribution Of Days Over Year")
    tm.set_ylabel("Days In month")
    tm.set_xlabel("Days In Year")
    st.pyplot()
v_line_d()

st.subheader('Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi chu k·ª≥ c·ªßa th√°ng')
def v_scatter_month():
    plt.figure(figsize=(10, 6))
    cyclic_month = sns.scatterplot(x="month_sin",y="month_cos",data=df, color="lightblue")
    cyclic_month.set_title("Cyclic Encoding of Month")
    cyclic_month.set_ylabel("Cosine Encoded Months")
    cyclic_month.set_xlabel("Sine Encoded Months")
    st.pyplot()
v_scatter_month()

st.subheader('Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi chu k·ª≥ c·ªßa ng√†y')
def v_scatter_day():
    # Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi chu k·ª≥ c·ªßa ng√†y
    plt.figure(figsize=(10, 6))
    cyclic_day = sns.scatterplot(x='day_sin',y='day_cos',data=df, color="#C2C4E2")
    cyclic_day.set_title("Cyclic Encoding of Day")
    cyclic_day.set_ylabel("Cosine Encoded Day")
    cyclic_day.set_xlabel("Sine Encoded Day")
    st.pyplot()
v_scatter_day()

st.header('TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU')

st.subheader('Ki·ªÉm tra gi√° tr·ªã null c·ªßa c·ªôt object')
st.code('''
for i in object_cols:
    print(i, df[i].isnull().sum())
''')
s = (df.dtypes == "object")
object_cols = list(s[s].index)
for i in object_cols:
    st.write(f"{i}: {df[i].isnull().sum()} missing values")

st.subheader('ƒêi·ªÅn gi√° tr·ªã tr·ªëng b·∫±ng mode c·ªßa c·ªôt trong kho·∫£ng gi√° tr·ªã')
st.code('''
for i in object_cols:
    df[i].fillna(df[i].mode()[0], inplace=True)
''')
for i in object_cols:
    df[i].fillna(df[i].mode()[0], inplace=True)

st.subheader('Ki·ªÉm tra gi√° tr·ªã null c·ªßa c·ªôt float64')
st.code('''
for i in num_cols:
    print(i, df[i].isnull().sum())
''')
t = (df.dtypes == "float64")
num_cols = list(t[t].index)
for i in num_cols:
    st.write(f"{i}: {df[i].isnull().sum()} missing values")

st.subheader(' ƒêi·ªÅn c√°c gi√° tr·ªã thi·∫øu b·∫±ng trung b√¨nh c·ªßa c·ªôt gi√° tr·ªã')
st.code('''
for i in num_cols:
    df[i].fillna(df[i].median(), inplace=True)
''')
for i in num_cols:
    df[i].fillna(df[i].median(), inplace=True)

st.subheader('Bi·ªÉu ƒë·ªì hi·ªÉn th·ªã l∆∞·ª£ng m∆∞a h·∫±ng nƒÉm')
def v_line_rainfall():
    sns.lineplot(x=df['year'], y=df['Rainfall'])
    st.pyplot()
v_line_rainfall()

st.subheader('Bi·ªÉu ƒë·ªì th·ªÉ hi·ªán t·ªëc ƒë·ªô gi√≥ c·ªßa t·ª´ng nƒÉm')
def v_bar_speed():
    plt.figure(figsize=(10,2))
    sns.barplot(x= df['year'], y= df['WindGustSpeed'], palette= sns.color_palette('viridis'))
    st.pyplot()
v_bar_speed()

st.subheader ('Bi·ªÉu ƒë·ªì hi·ªÉn th·ªã nhi·ªát ƒë·ªô min/max trung b√¨nh m√µi nƒÉm')
def v_line_temp():
    plt.figure(figsize=(12,8))
    average_min_temperature_per_year= df.groupby('year')['MinTemp'].mean()
    average_max_temperature_per_year= df.groupby('year')['MaxTemp'].mean()
    plt.plot(average_min_temperature_per_year.index, average_min_temperature_per_year.values, marker='o', linestyle='-', color='b', label='Min Temp')
    plt.plot(average_max_temperature_per_year.index, average_max_temperature_per_year.values, marker='o', linestyle='-', color='r', label='Max Temp')
    plt.legend()
    st.pyplot()
v_line_temp()

st.subheader('Chuy·ªÉn d·ªïi d·ªØ li·ªáu object')
st.code('''
label_encoder = LabelEncoder()
for i in object_cols:
    df[i] = label_encoder.fit_transform(df[i])
''')
label_encoder = LabelEncoder()
for i in object_cols:
    df[i] = label_encoder.fit_transform(df[i])

st.subheader('Hi·ªÉn th·ªã m√¥ h√¨nh th·ªëng k√™ c√°c thu·ªôc t√≠nh c·ªßa feature')
features = df.drop(['RainTomorrow', 'Date','month_sin','month_cos','day_sin','day_cos'], axis=1)# dropping target and extra columns

target = df[['RainTomorrow']]

#Set up a standard scaler for the features
col_names = list(features.columns)
s_scaler = StandardScaler()
features = s_scaler.fit_transform(features)
features = pd.DataFrame(features, columns=col_names)

st.dataframe(features.describe().T)

st.subheader('Ki·ªÉm tra ngo·∫°i lai (outlier)')
def p_v_outlier():
    colours = ["#D0DBEE", "#C2C4E2", "#EED4E5", "#D1E6DC", "#BDE2E2"]
    plt.figure(figsize=(10,5))
    sns.boxenplot(data = features,palette = colours)
    plt.xticks(rotation=90)
    st.pyplot()
p_v_outlier()

st.subheader('X√≥a b·ªè outlier')
features[["RainTomorrow"]] = target

#Dropping with outlier

features = features[(features["MinTemp"]<2.3)&(features["MinTemp"]>-2.3)]
features = features[(features["MaxTemp"]<2.3)&(features["MaxTemp"]>-2)]
features = features[(features["Rainfall"]<4.5)]
features = features[(features["Evaporation"]<2.8)]
features = features[(features["Sunshine"]<2.1)]
features = features[(features["WindGustSpeed"]<4)&(features["WindGustSpeed"]>-4)]
features = features[(features["WindSpeed9am"]<4)]
features = features[(features["WindSpeed3pm"]<2.5)]
features = features[(features["Humidity9am"]>-3)]
features = features[(features["Humidity3pm"]>-2.2)]
features = features[(features["Pressure9am"]< 2)&(features["Pressure9am"]>-2.7)]
features = features[(features["Pressure3pm"]< 2)&(features["Pressure3pm"]>-2.7)]
features = features[(features["Cloud9am"]<1.8)]
features = features[(features["Cloud3pm"]<2)]
features = features[(features["Temp9am"]<2.3)&(features["Temp9am"]>-2)]
features = features[(features["Temp3pm"]<2.3)&(features["Temp3pm"]>-2)]
def p_v_r_outlier():
    plt.figure(figsize=(10,5))
    sns.boxenplot(data = features)
    plt.xticks(rotation=90)
    st.pyplot()
p_v_r_outlier()

st.header('X√¢y d·ª±ng m√¥ h√¨nh')
X = features.drop(['RainTomorrow'], axis = 1)
y=features['RainTomorrow']# Splitting df into X and y # Splitting df into X and y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42,shuffle=True)
#Printing info on X and y
st.text('Info on X')
st.dataframe(X)
st.text('Info on y')
st.dataframe(y)

st.subheader('Linear Regression')
st.text('T·∫°o m√¥ h√¨nh')
st.code('''
model = LinearRegression()
model.fit(X_train, y_train)
y_pred_Linear = model.predict(X_test)
''')

model = LinearRegression()
model.fit(X_train, y_train)
y_pred_Linear = model.predict(X_test)
st.text('ƒê√°nh gi√° m√¥ h√¨nh(RMSE, MAE, R-squared)')
mae = mean_absolute_error(y_test, y_pred_Linear)
mse = mean_squared_error(y_test, y_pred_Linear)
r2 = r2_score(y_test, y_pred_Linear)
st.code('''
mae = mean_absolute_error(y_test, y_pred_Linear)
mse = mean_squared_error(y_test, y_pred_Linear)
r2 = r2_score(y_test, y_pred_Linear)
''')

st.write(f"Linear Regression Mean Squared Error: {mse:.2f}")
st.write(f"Linear Regression Mean Absolute Error: {mae:.2f}")
st.write(f"Linear Regression R-squared: {r2:.2f}")

st.subheader('Tr·ª±c quan h√≥a m√¥ h√¨nh d·ª± ƒëo√°n')
def v_Linear():
    x_ax=range(len(X_test))
    plt.scatter(x_ax, y_test, s=5, color="blue", label="ƒêi·ªÉm th·ª±c")
    plt.plot(x_ax, y_pred_Linear, lw=1.5, color="red", label="ƒêi·ªÉm d·ª± ƒëo√°n")
    plt.legend()
    st.pyplot()
v_Linear()

st.subheader('Linear Regression')
st.text('T·∫°o m√¥ h√¨nh')
st.code('''
# T·∫°o m√¥ h√¨nh Lasso
lasso_model = Lasso(alpha=1.0)

# Fit the model to the training data
lasso_model.fit(X_train, y_train)

# Make predictions on the test set
lasso_predictions = lasso_model.predict(X_test)

''')
# T·∫°o m√¥ h√¨nh Lasso
lasso_model = Lasso(alpha=1.0)

# Fit the model to the training data
lasso_model.fit(X_train, y_train)

# Make predictions on the test set
lasso_predictions = lasso_model.predict(X_test)
st.text('ƒê√°nh gi√° m√¥ h√¨nh(RMSE, MAE, R-squared)')
mse = mean_squared_error(y_test, lasso_predictions)
mae = mean_absolute_error(y_test, lasso_predictions)
r2 = r2_score(y_test, lasso_predictions)
st.code('''
mse = mean_squared_error(y_test, lasso_predictions)
mae = mean_absolute_error(y_test, lasso_predictions)
r2 = r2_score(y_test, lasso_predictions)
''')

st.write(f"Lasso Regression Mean Squared Error: {mse:.2f}")
st.write(f"Lasso Regression Mean Absolute Error: {mae:.2f}")
st.write(f"Lasso Regression R-squared: {r2:.2f}")

# Define the parameter grid
param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}

# Initialize Lasso Regression model
lasso_model = Lasso()

# Initialize GridSearchCV
lasso_grid_search = GridSearchCV(lasso_model, param_grid, cv=5, scoring='neg_mean_squared_error')
lasso_grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_lasso_params = lasso_grid_search.best_params_

# Initialize Lasso model with best hyperparameters
best_lasso_model = Lasso(alpha=best_lasso_params['alpha'])
# Fit the Lasso model with the best hyperparameters
best_lasso_model.fit(X_train, y_train)

# Perform k-fold cross-validation
lasso_cv_scores = cross_val_score(best_lasso_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
lasso_rmse_scores = np.sqrt(-lasso_cv_scores)

lasso_predictions_k= best_lasso_model.predict(X_test)
st.text('Fit Lasso model v·ªõi the best hyperparameters')
st.code('''
# Define the parameter grid
param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}

# Initialize Lasso Regression model
lasso_model = Lasso()

# Initialize GridSearchCV
lasso_grid_search = GridSearchCV(lasso_model, param_grid, cv=5, scoring='neg_mean_squared_error')
lasso_grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_lasso_params = lasso_grid_search.best_params_

# Initialize Lasso model with best hyperparameters
best_lasso_model = Lasso(alpha=best_lasso_params['alpha'])
# Fit the Lasso model with the best hyperparameters
best_lasso_model.fit(X_train, y_train)

# Perform k-fold cross-validation
lasso_cv_scores = cross_val_score(best_lasso_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
lasso_rmse_scores = np.sqrt(-lasso_cv_scores)
''')
st.text('ƒê√°nh gi√° l·∫°i m√¥ h√¨nh')

# Print the metrics
lasso_predictions_k= best_lasso_model.predict(X_test)
st.write(f"Test RMSE: {np.sqrt(mean_squared_error(y_test, lasso_predictions_k)):.3f}")
st.write(f"Test MAE: {mean_absolute_error(y_test, lasso_predictions_k):.3f}")
st.write(f"Test R-squared: {r2_score(y_test, lasso_predictions_k):.3f}")

st.subheader('Tr·ª±c quan m√¥ h√¨nh LASSO')
def v_lasso():
    x_ax=range(len(X_test))
    plt.plot(x_ax, lasso_predictions_k, lw=1.5, color="red", label="ƒêi·ªÉm d·ª± ƒëo√°n", zorder=1)
    plt.scatter(x_ax, y_test, s=5, color="blue", label="ƒêi·ªÉm th·ª±c", zorder=2)
    plt.legend()
    st.pyplot()
v_lasso()

st.header('Ridge Regression')
st.text('T·∫°o m√¥ h√¨nh Ridge')
st.code('''
#T·∫°o m√¥ h√¨nh ridge
ridge_model = Ridge(alpha=1.0)

# Fit the model to the training data
ridge_model.fit(X_train, y_train)

# Make predictions on the test set
ridge_predictions = ridge_model.predict(X_test)

# Evaluate the model's performance
mse = mean_squared_error(y_test, ridge_predictions)
mae = mean_absolute_error(y_test, ridge_predictions)
r2 = r2_score(y_test, ridge_predictions)
''')
#T·∫°o m√¥ h√¨nh ridge
ridge_model = Ridge(alpha=1.0)

# Fit the model to the training data
ridge_model.fit(X_train, y_train)

# Make predictions on the test set
ridge_predictions = ridge_model.predict(X_test)

# Evaluate the model's performance
mse = mean_squared_error(y_test, ridge_predictions)
mae = mean_absolute_error(y_test, ridge_predictions)
r2 = r2_score(y_test, ridge_predictions)

st.text('ƒê√°nh gi√° m√¥ h√¨nh Ridge')
st.write(f"Ridge Regression Mean Squared Error: {mse:.2f}")
st.write(f"Ridge Regression Mean Absolute Error: {mae:.2f}")
st.write(f"Ridge Regression R-squared: {r2:.2f}")

st.text('Fit model Ridge v·ªõi best hyperparameters')
st.code('''
# Define the parameter grid
param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}

# Initialize Ridge Regression model
ridge_model = Ridge()

# Initialize GridSearchCV
ridge_grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')
ridge_grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_ridge_params = ridge_grid_search.best_params_

# Initialize Ridge model with best hyperparameters
best_ridge_model = Ridge(alpha=best_ridge_params['alpha'])
# Fit the Ridge model with the best hyperparameters
best_ridge_model.fit(X_train, y_train)

# Perform k-fold cross-validation
ridge_cv_scores = cross_val_score(best_ridge_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
ridge_rmse_scores = np.sqrt(-ridge_cv_scores)
        ''')

# Define the parameter grid
param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}

# Initialize Ridge Regression model
ridge_model = Ridge()

# Initialize GridSearchCV
ridge_grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')
ridge_grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_ridge_params = ridge_grid_search.best_params_

# Initialize Ridge model with best hyperparameters
best_ridge_model = Ridge(alpha=best_ridge_params['alpha'])
# Fit the Ridge model with the best hyperparameters
best_ridge_model.fit(X_train, y_train)

# Perform k-fold cross-validation
ridge_cv_scores = cross_val_score(best_ridge_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
ridge_rmse_scores = np.sqrt(-ridge_cv_scores)

st.text('ƒê√°nh gi√° l·∫°i m√¥ h√¨nh Ridge')
ridge_predictions_k = best_ridge_model.predict(X_test)
st.write(f"Test RMSE: {np.sqrt(mean_squared_error(y_test, ridge_predictions_k)):.3f}")
st.write(f"Test MAE: {mean_absolute_error(y_test, ridge_predictions_k):.3f}")
st.write(f"Test R-squared:, {r2_score(y_test, ridge_predictions_k):.3f}")

st.text('Tr·ª±c quan h√≥a m√¥ h√¨nh')
def v_ridge():
    x_ax=range(len(X_test))
    plt.scatter(x_ax, y_test, s=5, color="blue", label="ƒêi·ªÉm th·ª±c",zorder =2)
    plt.plot(x_ax, ridge_predictions_k, lw=1.5, color="green", label="ƒêi·ªÉm d·ª± ƒëo√°n", zorder =1)
    plt.legend()
    st.pyplot()
v_ridge()

# st.header("Logistic Regression")
# st.text('T·∫°o m√¥ h√¨nh')
# st.code('''
# # T·∫°o m√¥ h√¨nh h·ªìi quy
# model_Logistic = LogisticRegression(solver='liblinear')
# model_Logistic.fit(X_train,y_train)
# #D·ª± ƒëo√°n
# y_predict_Logistic = model_Logistic.predict(X_test)
# r2 = r2_score(y_predict_Logistic,y_test)
# x_ax=range(len(X_test))
# mean_adjusted_r2 = np.mean(r2)
# mean = mean_squared_error(y_predict_Logistic,y_test)
# trainScore = math.sqrt(mean)

# ''')
# # T·∫°o m√¥ h√¨nh h·ªìi quy
# model_Logistic = LogisticRegression(solver='liblinear')
# model_Logistic.fit(X_train,y_train)
# #D·ª± ƒëo√°n
# y_predict_Logistic = model_Logistic.predict(X_test)
# r2 = r2_score(y_predict_Logistic,y_test)
# x_ax=range(len(X_test))
# mean_adjusted_r2 = np.mean(r2)
# mean = mean_squared_error(y_predict_Logistic,y_test)
# trainScore = math.sqrt(mean)

# st.text('ƒê√°nh gi√° m√¥ h√¨nh')
# st.write(f'RMSE :,{trainScore:.2f}')
# st.write(f'Mean Adjusted R-squared = {mean_adjusted_r2:.2f}')
# st.write(f"X√°c ƒë·ªãnh ƒë·ªô ch√≠nh x√°c,{accuracy_score(y_test,y_predict_Logistic):.2f}")

# st.text('Fit model Logistic v·ªõi best hyperparameters')
# st.code('''
# # Define the parameter grid
# param_grid = {'n_jobs': [0.001, 0.01, 0.1, 1, 10, 100]}

# # Initialize Ridge Regression model
# logis_model = LogisticRegression()

# # Initialize GridSearchCV
# logis_grid_search = GridSearchCV(logis_model, param_grid, cv=5, scoring='neg_mean_squared_error')
# logis_grid_search.fit(X_train, y_train)

# # Get the best hyperparameters
# best_logis_params = logis_grid_search.best_params_

# # Initialize Ridge model with best hyperparameters
# best_logis_model = LogisticRegression(n_jobs=best_logis_params['n_jobs'])
# # Fit the Ridge model with the best hyperparameters
# best_logis_model.fit(X_train, y_train)

# # Perform k-fold cross-validation
# logis_cv_scores = cross_val_score(best_logis_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
# logis_rmse_scores = np.sqrt(-logis_cv_scores)
# logis_predictions_k = best_logis_model.predict(X_test)
# ''')
# # Define the parameter grid
# param_grid = {'n_jobs': [0.001, 0.01, 0.1, 1, 10, 100]}

# # Initialize Ridge Regression model
# logis_model = LogisticRegression()

# # Initialize GridSearchCV
# logis_grid_search = GridSearchCV(logis_model, param_grid, cv=5, scoring='neg_mean_squared_error')
# logis_grid_search.fit(X_train, y_train)

# # Get the best hyperparameters
# best_logis_params = logis_grid_search.best_params_

# # Initialize Ridge model with best hyperparameters
# best_logis_model = LogisticRegression(n_jobs=best_logis_params['n_jobs'])
# # Fit the Ridge model with the best hyperparameters
# best_logis_model.fit(X_train, y_train)

# Perform k-fold cross-validation
# logis_cv_scores = cross_val_score(best_logis_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
# logis_rmse_scores = np.sqrt(-logis_cv_scores)
# logis_predictions_k = best_logis_model.predict(X_test)

# st.text('ƒê√°nh gi√° l·∫°i m√¥ h√¨nh')
# st.write(f"Test RMSE:, {np.sqrt(mean_squared_error(y_test, logis_predictions_k)):.2f}")
# st.write(f"Test MAE:, {mean_absolute_error(y_test, logis_predictions_k):.2f}")
# st.write(f"Test R-squared:, {r2_score(y_test, logis_predictions_k):.2f}")

# st.text('Tr·ª±c quan h√≥a m√¥ h√¨nh')
# def v_logic():
#     plt.scatter(x_ax, y_test, s=5, color="red", label="ƒêi·ªÉm th·ª±c",zorder= 2)
#     plt.plot(x_ax, logis_predictions_k, lw=1.5, color="green", label="ƒêi·ªÉm d·ª± ƒëo√°n",zorder =1)
#     plt.legend()
#     st.pyplot()
# v_logic()

st.header('PREDICTION WITH MODELS')
st.subheader('ƒêi·ªÅn d·ªØu li·ªáu ƒë·ªÉ d·ª± ƒëo√°n')
require_data_pre=[]

New_value=[2,	13.4,	22.9,	0.6,	4.8,	8.4,	13,	44.0,	13,	14,	20.0,	24.0,	71.0,	22.0,	1007.7,	1007.1,	8.0,	5.0,	16.9,	21.8, 0, 2008,	12,	1]

for i,z in zip(X_train.columns, New_value):
    user_input = st.number_input(i)
    require_data_pre.append(st.number_input(i,value=z))
st.write(require_data_pre)

require_data_pre = np.array(require_data_pre).reshape(1,-1)
require_data_pre= s_scaler.transform(require_data_pre)

st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n c·ªßa c√°c m√¥ h√¨nh")
st.caption('Linear Regression')
require_data_pre_linear = model.predict(require_data_pre)

threshold = 0.5
binary_ex_predict = (require_data_pre_linear >= threshold).astype(int)
st.write(f"Predictions (continuous):, {require_data_pre_linear[0]:.2f}")
st.write(f"Predictions (binary):, {binary_ex_predict[0]:.2f}")

st.caption('LASSO Regression')
LA_predict = best_lasso_model.predict(require_data_pre)
st.write(f'Prediction: ,{LA_predict[0]:.2f}')

st.caption('Ridge Regression')
Rd_predict = best_ridge_model.predict(require_data_pre)
st.write(f'Prediction: ,{Rd_predict[0]:.2f}')
